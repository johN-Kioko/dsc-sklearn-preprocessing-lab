{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing with scikit-learn - Cumulative Lab\n",
    "\n",
    "## Introduction\n",
    "In this cumulative lab, you'll practice applying various preprocessing techniques with scikit-learn (`sklearn`) to the Ames Housing dataset in order to prepare the data for predictive modeling. The main emphasis here is on preprocessing (not EDA or modeling theory), so we will skip over most of the visualization and metrics steps that you would take in an actual modeling process.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Practice identifying which preprocessing technique to use\n",
    "* Practice filtering down to relevant columns\n",
    "* Practice applying `sklearn.impute` to fill in missing values\n",
    "* Practice applying `sklearn.preprocessing`:\n",
    "  * `OrdinalEncoder` for converting binary categories to 0 and 1 within a single column\n",
    "  * `OneHotEncoder` for creating multiple \"dummy\" columns to represent multiple categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task: Prepare the Ames Housing Dataset for Modeling\n",
    "\n",
    "![house in Ames](https://curriculum-content.s3.amazonaws.com/data-science/images/ames_house.jpg)\n",
    "\n",
    "<span>Photo by <a href=\"https://unsplash.com/@kjkempt17?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Kyle Kempt</a> on <a href=\"https://unsplash.com/s/photos/ames?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "#### 1. Drop Irrelevant Columns\n",
    "\n",
    "For the purposes of this lab, we will only be using a subset of all of the features present in the Ames Housing dataset. In this step you will drop all irrelevant columns.\n",
    "\n",
    "#### 2. Handle Missing Values\n",
    "\n",
    "Often for reasons outside of a data scientist's control, datasets are missing some values. In this step you will assess the presence of NaN values in our subset of data, and use `MissingIndicator` and `SimpleImputer` from the `sklearn.impute` submodule to handle any missing values.\n",
    "\n",
    "#### 3. Convert Categorical Features into Numbers\n",
    "\n",
    "A built-in assumption of the scikit-learn library is that all data being fed into a machine learning model is already in a numeric format, otherwise you will get a `ValueError` when you try to fit a model. In this step you will use an `OrdinalEncoder` to replace data within individual non-numeric columns with 0s and 1s, and a `OneHotEncoder` to replace columns containing more than 2 categories with multiple \"dummy\" columns containing 0s and 1s.\n",
    "\n",
    "At this point, a scikit-learn model should be able to run without errors!\n",
    "\n",
    "#### 4. Preprocess Test Data\n",
    "\n",
    "Apply Steps 1-3 to the test data in order to perform a final model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Setup\n",
    "\n",
    "### Getting the Data\n",
    "\n",
    "In the cell below, we import the `pandas` library, open the CSV containing the Ames Housing data as a pandas `DataFrame`, and inspect its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:52.510867500Z",
     "start_time": "2023-11-21T10:07:50.502687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n...    ...         ...      ...          ...      ...    ...   ...      ...   \n1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n\n     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n...          ...       ...  ...      ...    ...    ...         ...     ...   \n1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n\n     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n0         2   2008        WD         Normal     208500  \n1         5   2007        WD         Normal     181500  \n2         9   2008        WD         Normal     223500  \n3         2   2006        WD        Abnorml     140000  \n4        12   2008        WD         Normal     250000  \n...     ...    ...       ...            ...        ...  \n1455      8   2007        WD         Normal     175000  \n1456      2   2010        WD         Normal     210000  \n1457      5   2010        WD         Normal     266500  \n1458      4   2010        WD         Normal     142125  \n1459      6   2008        WD         Normal     147500  \n\n[1460 rows x 81 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>1456</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>175000</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>1457</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>210000</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>1458</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdPrv</td>\n      <td>Shed</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>266500</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>1459</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>142125</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>1460</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>147500</td>\n    </tr>\n  </tbody>\n</table>\n<p>1460 rows × 81 columns</p>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/ames.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:52.560072500Z",
     "start_time": "2023-11-21T10:07:50.573422100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\ncount  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \nmean    730.500000    56.897260    70.049958   10516.828082     6.099315   \nstd     421.610009    42.300571    24.284752    9981.264932     1.382997   \nmin       1.000000    20.000000    21.000000    1300.000000     1.000000   \n25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \nmax    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n\n       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\ncount  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \nmean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \nstd       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \nmin       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \nmax       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n\n        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\ncount  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \nmean     94.244521    46.660274      21.954110     3.409589    15.060959   \nstd     125.338794    66.256028      61.119149    29.317331    55.757415   \nmin       0.000000     0.000000       0.000000     0.000000     0.000000   \n25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n75%     168.000000    68.000000       0.000000     0.000000     0.000000   \nmax     857.000000   547.000000     552.000000   508.000000   480.000000   \n\n          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \ncount  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \nmean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \nstd      40.177307    496.123024     2.703626     1.328095   79442.502883  \nmin       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \nmax     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n\n[8 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>...</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1201.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1452.000000</td>\n      <td>1460.000000</td>\n      <td>...</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>730.500000</td>\n      <td>56.897260</td>\n      <td>70.049958</td>\n      <td>10516.828082</td>\n      <td>6.099315</td>\n      <td>5.575342</td>\n      <td>1971.267808</td>\n      <td>1984.865753</td>\n      <td>103.685262</td>\n      <td>443.639726</td>\n      <td>...</td>\n      <td>94.244521</td>\n      <td>46.660274</td>\n      <td>21.954110</td>\n      <td>3.409589</td>\n      <td>15.060959</td>\n      <td>2.758904</td>\n      <td>43.489041</td>\n      <td>6.321918</td>\n      <td>2007.815753</td>\n      <td>180921.195890</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>421.610009</td>\n      <td>42.300571</td>\n      <td>24.284752</td>\n      <td>9981.264932</td>\n      <td>1.382997</td>\n      <td>1.112799</td>\n      <td>30.202904</td>\n      <td>20.645407</td>\n      <td>181.066207</td>\n      <td>456.098091</td>\n      <td>...</td>\n      <td>125.338794</td>\n      <td>66.256028</td>\n      <td>61.119149</td>\n      <td>29.317331</td>\n      <td>55.757415</td>\n      <td>40.177307</td>\n      <td>496.123024</td>\n      <td>2.703626</td>\n      <td>1.328095</td>\n      <td>79442.502883</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>20.000000</td>\n      <td>21.000000</td>\n      <td>1300.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1872.000000</td>\n      <td>1950.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2006.000000</td>\n      <td>34900.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>365.750000</td>\n      <td>20.000000</td>\n      <td>59.000000</td>\n      <td>7553.500000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>1954.000000</td>\n      <td>1967.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>2007.000000</td>\n      <td>129975.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>730.500000</td>\n      <td>50.000000</td>\n      <td>69.000000</td>\n      <td>9478.500000</td>\n      <td>6.000000</td>\n      <td>5.000000</td>\n      <td>1973.000000</td>\n      <td>1994.000000</td>\n      <td>0.000000</td>\n      <td>383.500000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>2008.000000</td>\n      <td>163000.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1095.250000</td>\n      <td>70.000000</td>\n      <td>80.000000</td>\n      <td>11601.500000</td>\n      <td>7.000000</td>\n      <td>6.000000</td>\n      <td>2000.000000</td>\n      <td>2004.000000</td>\n      <td>166.000000</td>\n      <td>712.250000</td>\n      <td>...</td>\n      <td>168.000000</td>\n      <td>68.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>2009.000000</td>\n      <td>214000.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1460.000000</td>\n      <td>190.000000</td>\n      <td>313.000000</td>\n      <td>215245.000000</td>\n      <td>10.000000</td>\n      <td>9.000000</td>\n      <td>2010.000000</td>\n      <td>2010.000000</td>\n      <td>1600.000000</td>\n      <td>5644.000000</td>\n      <td>...</td>\n      <td>857.000000</td>\n      <td>547.000000</td>\n      <td>552.000000</td>\n      <td>508.000000</td>\n      <td>480.000000</td>\n      <td>738.000000</td>\n      <td>15500.000000</td>\n      <td>12.000000</td>\n      <td>2010.000000</td>\n      <td>755000.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 38 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction target for this analysis is the sale price of the home, so we separate the data into `X` and `y` accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:52.561069700Z",
     "start_time": "2023-11-21T10:07:50.669071600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.drop(\"SalePrice\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we separate the data into a train set and a test set prior to performing any preprocessing steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:52.584007800Z",
     "start_time": "2023-11-21T10:07:50.679049800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If you are working through this lab and you just want to start over with the original value for `X_train`, re-run the cell above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:52.585711800Z",
     "start_time": "2023-11-21T10:07:50.708061900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train is a DataFrame with 1095 rows and 80 columns\n",
      "y_train is a Series with 1095 values\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "print(f\"X_train is a DataFrame with {X_train.shape[0]} rows and {X_train.shape[1]} columns\")\n",
    "print(f\"y_train is a Series with {y_train.shape[0]} values\")\n",
    "\n",
    "# We always should have the same number of rows in X as values in y\n",
    "assert X_train.shape[0] == y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting a Model\n",
    "\n",
    "For this lab we will be using a `LinearRegression` model from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)).\n",
    "\n",
    "Right now, we have not done any preprocessing, so we expect that trying to fit a model will fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:52.621651100Z",
     "start_time": "2023-11-21T10:07:50.721583900Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'RL'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13320\\4275048384.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Run this cell without changes\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear_model\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLinearRegression\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mLinearRegression\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1147\u001B[0m                 skip_parameter_validation=(\n\u001B[0;32m   1148\u001B[0m                     \u001B[0mprefer_skip_nested_validation\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mglobal_skip_validation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m                 )\n\u001B[0;32m   1150\u001B[0m             ):\n\u001B[1;32m-> 1151\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfit_method\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    674\u001B[0m         \u001B[0mn_jobs_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    675\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    676\u001B[0m         \u001B[0maccept_sparse\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpositive\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m\"csr\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"csc\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"coo\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    677\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 678\u001B[1;33m         X, y = self._validate_data(\n\u001B[0m\u001B[0;32m    679\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_numeric\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmulti_output\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    680\u001B[0m         )\n\u001B[0;32m    681\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    617\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[1;34m\"estimator\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcheck_y_params\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    618\u001B[0m                     \u001B[0mcheck_y_params\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mdefault_check_params\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    619\u001B[0m                 \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"y\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    620\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 621\u001B[1;33m                 \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    622\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    623\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    624\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mcheck_params\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"ensure_2d\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1143\u001B[0m         raise ValueError(\n\u001B[0;32m   1144\u001B[0m             \u001B[1;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1145\u001B[0m         )\n\u001B[0;32m   1146\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1147\u001B[1;33m     X = check_array(\n\u001B[0m\u001B[0;32m   1148\u001B[0m         \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m         \u001B[0maccept_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1150\u001B[0m         \u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maccept_large_sparse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    914\u001B[0m                         )\n\u001B[0;32m    915\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    916\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    917\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_asarray_with_order\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mxp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 918\u001B[1;33m             \u001B[1;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    919\u001B[0m                 raise ValueError(\n\u001B[0;32m    920\u001B[0m                     \u001B[1;34m\"Complex data not supported\\n{}\\n\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    921\u001B[0m                 ) from complex_warning\n",
      "\u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[0;32m    376\u001B[0m         \u001B[1;31m# Use NumPy API to support order\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    377\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcopy\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    378\u001B[0m             \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    379\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 380\u001B[1;33m             \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    381\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    382\u001B[0m         \u001B[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    383\u001B[0m         \u001B[1;31m# container that is consistent with the input's namespace.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m   1996\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnpt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDTypeLike\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1997\u001B[0m         \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1998\u001B[1;33m         \u001B[0marr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1999\u001B[0m         if (\n\u001B[0;32m   2000\u001B[0m             \u001B[0mastype_is_view\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2001\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0musing_copy_on_write\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'RL'"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we got `ValueError: could not convert string to float: 'RL'`.\n",
    "\n",
    "In order to fit a scikit-learn model, all values must be numeric, and the third column of our full dataset (`MSZoning`) contains values like `'RL'` and `'RH'`, which are strings. So this error was expected, but after some preprocessing, this model will work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Drop Irrelevant Columns\n",
    "\n",
    "For the purpose of this analysis, we'll only use the following columns, described by `relevant_columns`. You can find the full description of their values in the file `data/data_description.txt` included in this repository.\n",
    "\n",
    "In the cell below, reassign `X_train` so that it only contains the columns in `relevant_columns`.\n",
    "\n",
    "**Hint:** Even though we describe this as \"dropping\" irrelevant columns, it's easier if you invert the logic, so that we are only keeping relevant columns, rather than using the `.drop()` method. It is possible to use the `.drop()` method if you really want to, but first you would need to create a list of the column names that you don't want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:50.785048900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "# Declare relevant columns\n",
    "relevant_columns = [\n",
    "    'LotFrontage',  # Linear feet of street connected to property\n",
    "    'LotArea',      # Lot size in square feet\n",
    "    'Street',       # Type of road access to property\n",
    "    'OverallQual',  # Rates the overall material and finish of the house\n",
    "    'OverallCond',  # Rates the overall condition of the house\n",
    "    'YearBuilt',    # Original construction date\n",
    "    'YearRemodAdd', # Remodel date (same as construction date if no remodeling or additions)\n",
    "    'GrLivArea',    # Above grade (ground) living area square feet\n",
    "    'FullBath',     # Full bathrooms above grade\n",
    "    'BedroomAbvGr', # Bedrooms above grade (does NOT include basement bedrooms)\n",
    "    'TotRmsAbvGrd', # Total rooms above grade (does not include bathrooms)\n",
    "    'Fireplaces',   # Number of fireplaces\n",
    "    'FireplaceQu',  # Fireplace quality\n",
    "    'MoSold',       # Month Sold (MM)\n",
    "    'YrSold'        # Year Sold (YYYY)\n",
    "]\n",
    "\n",
    "# Reassign X_train so that it only contains relevant columns\n",
    "X_train = X_train.loc[:, relevant_columns]\n",
    "\n",
    "# Visually inspect X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the new shape is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:50.787042700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# X_train should have the same number of rows as before\n",
    "assert X_train.shape[0] == 1095\n",
    "\n",
    "# Now X_train should only have as many columns as relevant_columns\n",
    "assert X_train.shape[1] == len(relevant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Handle Missing Values\n",
    "\n",
    "In the cell below, we check to see if there are any NaNs in the selected subset of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:50.791032500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it looks like we have some NaNs in `LotFrontage` and `FireplaceQu`.\n",
    "\n",
    "Before we proceed to fill in those values, we need to ask: **do these NaNs actually represent** ***missing*** **values, or is there some real value/category being represented by NaN?**\n",
    "\n",
    "### Fireplace Quality\n",
    "\n",
    "To start with, let's look at `FireplaceQu`, which means \"Fireplace Quality\". Why might we have NaN fireplace quality?\n",
    "\n",
    "Well, some properties don't have fireplaces!\n",
    "\n",
    "Let's confirm this guess with a little more analysis.\n",
    "\n",
    "First, we know that there are 512 records with NaN fireplace quality. How many records are there with zero fireplaces?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:50.797016500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "X_train[X_train[\"Fireplaces\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that's 512 rows, same as the number of NaN `FireplaceQu` records. To double-check, let's query for that combination of factors (zero fireplaces and `FireplaceQu` is NaN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:50.801006Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "X_train[\n",
    "    (X_train[\"Fireplaces\"] == 0) &\n",
    "    (X_train[\"FireplaceQu\"].isna())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, still 512 records. So, NaN fireplace quality is not actually information that is missing from our dataset, it is a genuine category which means \"fireplace quality is not applicable\". This interpretation aligns with what we see in `data/data_description.txt`:\n",
    "\n",
    "```\n",
    "...\n",
    "FireplaceQu: Fireplace quality\n",
    "\n",
    "       Ex\tExcellent - Exceptional Masonry Fireplace\n",
    "       Gd\tGood - Masonry Fireplace in main level\n",
    "       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n",
    "       Fa\tFair - Prefabricated Fireplace in basement\n",
    "       Po\tPoor - Ben Franklin Stove\n",
    "       NA\tNo Fireplace\n",
    "...\n",
    "```\n",
    "\n",
    "So, let's replace those NaNs with the string \"N/A\" to indicate that this is a real category, not missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:50.812973400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "X_train[\"FireplaceQu\"] = X_train[\"FireplaceQu\"].fillna(\"N/A\")\n",
    "X_train[\"FireplaceQu\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually we will still need to perform some preprocessing to prepare the `FireplaceQu` column for modeling (because models require numeric inputs rather than inputs of type `object`), but we don't need to worry about filling in missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lot Frontage\n",
    "\n",
    "Now let's look at `LotFrontage` — it's possible that NaN is also a genuine category here, and it's possible that it's just missing data instead. Let's apply some domain understanding to understand whether it's possible that lot frontage can be N/A just like fireplace quality can be N/A.\n",
    "\n",
    "Lot frontage is defined as the \"Linear feet of street connected to property\", i.e. how much of the property runs directly along a road. The amount of frontage required for a property depends on its zoning. Let's look at the zoning of all records with NaN for `LotFrontage`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:52.658152400Z",
     "start_time": "2023-11-21T10:07:50.844888500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MSZoning\nRL    229\nRM     19\nFV      8\nRH      3\nName: count, dtype: int64"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "df[df[\"LotFrontage\"].isna()][\"MSZoning\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have RL (residential low density), RM (residential medium density), FV (floating village residential), and RH (residential high density). Looking at the building codes from the City of Ames, it appears that all of these zones require at least 24 feet of frontage.\n",
    "\n",
    "Nevertheless, we can't assume that all properties have frontage just because the zoning regulations require it. Maybe these properties predate the regulations, or they received some kind of variance permitting them to get around the requirement. **It's still not as clear here as it was with the fireplaces whether this is a genuine \"not applicable\" kind of NaN or a \"missing information\" kind of NaN.**\n",
    "\n",
    "In a case like this, we can take a double approach:\n",
    "\n",
    "1. Make a new column in the dataset that simply represents whether `LotFrontage` was originally NaN\n",
    "2. Fill in the NaN values of `LotFrontage` with median frontage in preparation for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Indicator for `LotFrontage`\n",
    "\n",
    "First, we import `sklearn.impute.MissingIndicator` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html)). The goal of using a `MissingIndicator` is creating a new column to represent which values were NaN (or some other \"missing\" value) in the original dataset, in case NaN ends up being a meaningful indicator rather than a random missing bit of data.\n",
    "\n",
    "A `MissingIndicator` is a scikit-learn transformer, meaning that we will use the standard steps for any scikit-learn transformer:\n",
    "\n",
    "1. Identify data to be transformed (typically not every column is passed to every transformer)\n",
    "2. Instantiate the transformer object\n",
    "3. Fit the transformer object (on training data only)\n",
    "4. Transform data using the transformer object\n",
    "5. Add the transformed data to the other data that was not transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:52.668091300Z",
     "start_time": "2023-11-21T10:07:50.890909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[False],\n       [False],\n       [False],\n       ...,\n       [False],\n       [False],\n       [False]])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace None with appropriate code\n",
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "# (1) Identify data to be transformed\n",
    "# We only want missing indicators for LotFrontage\n",
    "frontage_train = X_train[[\"LotFrontage\"]]\n",
    "\n",
    "# (2) Instantiate the transformer object\n",
    "missing_indicator = MissingIndicator()\n",
    "\n",
    "# (3) Fit the transformer object on frontage_train\n",
    "missing_indicator.fit(frontage_train)\n",
    "\n",
    "# (4) Transform frontage_train and assign the result\n",
    "# to frontage_missing_train\n",
    "frontage_missing_train = missing_indicator.transform(frontage_train)\n",
    "\n",
    "# Visually inspect frontage_missing_train\n",
    "frontage_missing_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of transforming `frontage_train` should be an array of arrays, each containing `True` or `False`. Make sure the `assert`s pass before moving on to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:52.686350600Z",
     "start_time": "2023-11-21T10:07:50.919797600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "import numpy as np\n",
    "\n",
    "# frontage_missing_train should be a NumPy array\n",
    "assert type(frontage_missing_train) == np.ndarray\n",
    "\n",
    "# We should have the same number of rows as the full X_train\n",
    "assert frontage_missing_train.shape[0] == X_train.shape[0]\n",
    "\n",
    "# But we should only have 1 column\n",
    "assert frontage_missing_train.shape[1] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add this new information as a new column of `X_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:52.730103700Z",
     "start_time": "2023-11-21T10:07:50.942913400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n1023  1024         120       RL         43.0     3182   Pave   NaN      Reg   \n810    811          20       RL         78.0    10140   Pave   NaN      Reg   \n1384  1385          50       RL         60.0     9060   Pave   NaN      Reg   \n626    627          20       RL          NaN    12342   Pave   NaN      IR1   \n813    814          20       RL         75.0     9750   Pave   NaN      Reg   \n...    ...         ...      ...          ...      ...    ...   ...      ...   \n1095  1096          20       RL         78.0     9317   Pave   NaN      IR1   \n1130  1131          50       RL         65.0     7804   Pave   NaN      Reg   \n1294  1295          20       RL         60.0     8172   Pave   NaN      Reg   \n860    861          50       RL         55.0     7642   Pave   NaN      Reg   \n1126  1127         120       RL         53.0     3684   Pave   NaN      Reg   \n\n     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n1023         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n810          Lvl    AllPub  ...      648     Fa  GdPrv         NaN       0   \n1384         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n626          Lvl    AllPub  ...        0    NaN   GdWo        Shed     600   \n813          Lvl    AllPub  ...        0    NaN    NaN        Shed     500   \n...          ...       ...  ...      ...    ...    ...         ...     ...   \n1095         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1130         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n1294         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n860          Lvl    AllPub  ...        0    NaN  GdPrv         NaN       0   \n1126         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n\n     MoSold YrSold  SaleType  SaleCondition  LotFrontage_Missing  \n1023      5   2008        WD         Normal                False  \n810       1   2006        WD         Normal                False  \n1384     10   2009        WD         Normal                False  \n626       8   2007        WD         Normal                 True  \n813       4   2007       COD         Normal                False  \n...     ...    ...       ...            ...                  ...  \n1095      3   2007        WD         Normal                False  \n1130     12   2009        WD         Normal                False  \n1294      4   2006        WD         Normal                False  \n860       6   2007        WD         Normal                False  \n1126      6   2009        WD         Normal                False  \n\n[1095 rows x 81 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>LotFrontage_Missing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1023</th>\n      <td>1024</td>\n      <td>120</td>\n      <td>RL</td>\n      <td>43.0</td>\n      <td>3182</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>810</th>\n      <td>811</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>78.0</td>\n      <td>10140</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>648</td>\n      <td>Fa</td>\n      <td>GdPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1384</th>\n      <td>1385</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9060</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>626</th>\n      <td>627</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>12342</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdWo</td>\n      <td>Shed</td>\n      <td>600</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>813</th>\n      <td>814</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>9750</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Shed</td>\n      <td>500</td>\n      <td>4</td>\n      <td>2007</td>\n      <td>COD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>1096</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>78.0</td>\n      <td>9317</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>1131</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>7804</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>1295</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>8172</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>861</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>55.0</td>\n      <td>7642</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1126</th>\n      <td>1127</td>\n      <td>120</td>\n      <td>RL</td>\n      <td>53.0</td>\n      <td>3684</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>1095 rows × 81 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# (5) add the transformed data to the other data\n",
    "X_train[\"LotFrontage_Missing\"] = frontage_missing_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:50.989435200Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[59], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Run this cell without changes\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Now we should have 1 extra column compared to\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# our original subset\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m X_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(relevant_columns) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Now we should have 1 extra column compared to\n",
    "# our original subset\n",
    "assert X_train.shape[1] == len(relevant_columns) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Missing Values for LotFrontage\n",
    "\n",
    "Now that we have noted where missing values were originally present, let's use a `SimpleImputer` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)) to fill in those NaNs in the `LotFrontage` column.\n",
    "\n",
    "The process is very similar to the `MissingIndicator` process, except that we want to replace the original `LotFrontage` column with the transformed version instead of just adding a new column on.\n",
    "\n",
    "In the cell below, create and use a `SimpleImputer` with `strategy=\"median\"` to transform the value of `frontage_train` (declared above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.041055200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# (1) frontage_train was created previously, so we don't\n",
    "# need to extract the relevant data again\n",
    "\n",
    "# (2) Instantiate a SimpleImputer with strategy=\"median\"\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# (3) Fit the imputer on frontage_train\n",
    "imputer.fit(frontage_train)\n",
    "\n",
    "# (4) Transform frontage_train using the imputer and\n",
    "# assign the result to frontage_imputed_train\n",
    "frontage_imputed_train = imputer.transform(frontage_train)\n",
    "\n",
    "# Visually inspect frontage_imputed_train\n",
    "frontage_imputed_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can replace the original value of `LotFrontage` in `X_train` with the new value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.044047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# (5) Replace value of LotFrontage\n",
    "X_train[\"LotFrontage\"] = frontage_imputed_train\n",
    "\n",
    "# Visually inspect X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the shape of `X_train` should still be the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.047038700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "assert X_train.shape == (1095, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now our `X_train` no longer contains any NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:52.772810400Z",
     "start_time": "2023-11-21T10:07:51.055017900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Id                       0\nMSSubClass               0\nMSZoning                 0\nLotFrontage            200\nLotArea                  0\n                      ... \nMoSold                   0\nYrSold                   0\nSaleType                 0\nSaleCondition            0\nLotFrontage_Missing      0\nLength: 81, dtype: int64"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have completed Step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert Categorical Features into Numbers\n",
    "\n",
    "Despite dropping irrelevant columns and filling in those NaN values, if we feed the current `X_train` into our scikit-learn `LinearRegression` model, it will crash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.092505600Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'RL'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[61], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Run this cell without changes\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[0;32m   1150\u001B[0m ):\n\u001B[1;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001B[0m, in \u001B[0;36mLinearRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    674\u001B[0m n_jobs_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs\n\u001B[0;32m    676\u001B[0m accept_sparse \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpositive \u001B[38;5;28;01melse\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoo\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m--> 678\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[0;32m    679\u001B[0m     X, y, accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse, y_numeric\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, multi_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    680\u001B[0m )\n\u001B[0;32m    682\u001B[0m has_sw \u001B[38;5;241m=\u001B[39m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_sw:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    619\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    620\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 621\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    622\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1142\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1144\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1145\u001B[0m     )\n\u001B[1;32m-> 1147\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m   1148\u001B[0m     X,\n\u001B[0;32m   1149\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[0;32m   1150\u001B[0m     accept_large_sparse\u001B[38;5;241m=\u001B[39maccept_large_sparse,\n\u001B[0;32m   1151\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   1152\u001B[0m     order\u001B[38;5;241m=\u001B[39morder,\n\u001B[0;32m   1153\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m   1154\u001B[0m     force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite,\n\u001B[0;32m   1155\u001B[0m     ensure_2d\u001B[38;5;241m=\u001B[39mensure_2d,\n\u001B[0;32m   1156\u001B[0m     allow_nd\u001B[38;5;241m=\u001B[39mallow_nd,\n\u001B[0;32m   1157\u001B[0m     ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n\u001B[0;32m   1158\u001B[0m     ensure_min_features\u001B[38;5;241m=\u001B[39mensure_min_features,\n\u001B[0;32m   1159\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[0;32m   1160\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1161\u001B[0m )\n\u001B[0;32m   1163\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[0;32m   1165\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:838\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    833\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pandas_requires_conversion:\n\u001B[0;32m    834\u001B[0m     \u001B[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001B[39;00m\n\u001B[0;32m    835\u001B[0m     \u001B[38;5;66;03m# nans\u001B[39;00m\n\u001B[0;32m    836\u001B[0m     \u001B[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001B[39;00m\n\u001B[0;32m    837\u001B[0m     new_dtype \u001B[38;5;241m=\u001B[39m dtype_orig \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m dtype\n\u001B[1;32m--> 838\u001B[0m     array \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mastype(new_dtype)\n\u001B[0;32m    839\u001B[0m     \u001B[38;5;66;03m# Since we converted here, we do not need to convert again later\u001B[39;00m\n\u001B[0;32m    840\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6324\u001B[0m, in \u001B[0;36mNDFrame.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   6317\u001B[0m     results \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   6318\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miloc[:, i]\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m   6319\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns))\n\u001B[0;32m   6320\u001B[0m     ]\n\u001B[0;32m   6322\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6323\u001B[0m     \u001B[38;5;66;03m# else, only a single dtype is given\u001B[39;00m\n\u001B[1;32m-> 6324\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39mastype(dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m   6325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_data)\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6327\u001B[0m \u001B[38;5;66;03m# GH 33113: handle empty frame or series\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001B[0m, in \u001B[0;36mBaseBlockManager.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    449\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 451\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply(\n\u001B[0;32m    452\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    453\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m    454\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m    455\u001B[0m     errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    456\u001B[0m     using_cow\u001B[38;5;241m=\u001B[39musing_copy_on_write(),\n\u001B[0;32m    457\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001B[0m, in \u001B[0;36mBaseBlockManager.apply\u001B[1;34m(self, f, align_keys, **kwargs)\u001B[0m\n\u001B[0;32m    350\u001B[0m         applied \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mapply(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    351\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 352\u001B[0m         applied \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(b, f)(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     result_blocks \u001B[38;5;241m=\u001B[39m extend_blocks(applied, result_blocks)\n\u001B[0;32m    355\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mfrom_blocks(result_blocks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001B[0m, in \u001B[0;36mBlock.astype\u001B[1;34m(self, dtype, copy, errors, using_cow)\u001B[0m\n\u001B[0;32m    491\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;124;03mCoerce to the new dtype.\u001B[39;00m\n\u001B[0;32m    493\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    507\u001B[0m \u001B[38;5;124;03mBlock\u001B[39;00m\n\u001B[0;32m    508\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    509\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m--> 511\u001B[0m new_values \u001B[38;5;241m=\u001B[39m astype_array_safe(values, dtype, copy\u001B[38;5;241m=\u001B[39mcopy, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m    513\u001B[0m new_values \u001B[38;5;241m=\u001B[39m maybe_coerce_values(new_values)\n\u001B[0;32m    515\u001B[0m refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001B[0m, in \u001B[0;36mastype_array_safe\u001B[1;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    239\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtype\u001B[38;5;241m.\u001B[39mnumpy_dtype\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 242\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m astype_array(values, dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[0;32m    244\u001B[0m     \u001B[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001B[39;00m\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;66;03m#  trying to convert to float\u001B[39;00m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:187\u001B[0m, in \u001B[0;36mastype_array\u001B[1;34m(values, dtype, copy)\u001B[0m\n\u001B[0;32m    184\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 187\u001B[0m     values \u001B[38;5;241m=\u001B[39m _astype_nansafe(values, dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    189\u001B[0m \u001B[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001B[39;00m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, np\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(values\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138\u001B[0m, in \u001B[0;36m_astype_nansafe\u001B[1;34m(arr, dtype, copy, skipna)\u001B[0m\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(arr\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(dtype):\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001B[39;00m\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'RL'"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the first column to cause a problem is `Street`, which is documented like this:\n",
    "\n",
    "```\n",
    "...\n",
    "Street: Type of road access to property\n",
    "\n",
    "       Grvl\tGravel\t\n",
    "       Pave\tPaved\n",
    "...\n",
    "```\n",
    "\n",
    "Let's look at the full `X_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.322028100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our model is crashing because some of the columns are non-numeric.\n",
    "\n",
    "Anything that is already `float64` or `int64` will work with our model, but these features need to be converted:\n",
    "\n",
    "* `Street` (currently type `object`)\n",
    "* `FireplaceQu` (currently type `object`)\n",
    "* `LotFrontage_Missing` (currently type `bool`)\n",
    "\n",
    "There are two main approaches to converting these values, depending on whether there are 2 values (meaning the categorical variable can be converted into a single binary number) or more than 2 values (meaning we need to create extra columns to represent all categories).\n",
    "\n",
    "(If there is only 1 value, this is not a useful feature for the purposes of predictive analysis because every single row contains the same information.)\n",
    "\n",
    "In the cell below, we inspect the value counts of the specified features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.325788600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "print(X_train[\"Street\"].value_counts())\n",
    "print()\n",
    "print(X_train[\"FireplaceQu\"].value_counts())\n",
    "print()\n",
    "print(X_train[\"LotFrontage_Missing\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it looks like `Street` and `LotFrontage_Missing` have only 2 categories and can be converted into binary in place, whereas `FireplaceQu` has 6 categories and will need to be expanded into multiple columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Categories\n",
    "\n",
    "For binary categories, we will use an `OrdinalEncoder` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html)) to convert the categories of `Street` and `LotFrontage_Missing` into binary values (0s and 1s).\n",
    "\n",
    "Just like in Step 2 when we used the `MissingIndicator` and `SimpleImputer`, we will follow these steps:\n",
    "\n",
    "1. Identify data to be transformed\n",
    "2. Instantiate the transformer object\n",
    "3. Fit the transformer object (on training data only)\n",
    "4. Transform data using the transformer object\n",
    "5. Add the transformed data to the other data that was not transformed\n",
    "\n",
    "Let's start with transforming `Street`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.328780500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "# (0) import OrdinalEncoder from sklearn.preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# (1) Create a variable street_train that contains the\n",
    "# relevant column from X_train\n",
    "# (Use double brackets [[]] to get the appropriate shape)\n",
    "street_train = X_train[[\"Street\"]]\n",
    "\n",
    "# (2) Instantiate an OrdinalEncoder\n",
    "encoder_street = OrdinalEncoder()\n",
    "\n",
    "# (3) Fit the encoder on street_train\n",
    "encoder_street.fit(street_train)\n",
    "\n",
    "# Inspect the categories of the fitted encoder\n",
    "encoder_street.categories_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.categories_` attribute of `OrdinalEncoder` is only present once the `.fit` method has been called. (The trailing `_` indicates this convention.)\n",
    "\n",
    "What this tells us is that when `encoder_street` is used to transform the street data into 1s and 0s, `0` will mean `'Grvl'` (gravel) in the original data, and `1` will mean `'Pave'` (paved) in the original data.\n",
    "\n",
    "The eventual scikit-learn model only cares about the 1s and 0s, but this information can be useful for us to understand what our code is doing and help us debug when things go wrong.\n",
    "\n",
    "Now let's transform `street_train` with the fitted encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.331773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "# (4) Transform street_train using the encoder and\n",
    "# assign the result to street_encoded_train\n",
    "street_encoded_train = encoder_street.transform(street_train)\n",
    "\n",
    "# Flatten for appropriate shape\n",
    "street_encoded_train = street_encoded_train.flatten()\n",
    "\n",
    "# Visually inspect street_encoded_train\n",
    "street_encoded_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the values we see appear to be `1` right now, but that makes sense since there were only 4 properties with gravel (`0`) streets in `X_train`.\n",
    "\n",
    "Now let's replace the original `Street` column with the encoded version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.334763800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "# (5) Replace value of Street\n",
    "X_train[\"Street\"] = street_encoded_train\n",
    "\n",
    "# Visually inspect X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.337756400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now `Street` should by type `int64` instead of `object`.\n",
    "\n",
    "Now, repeat the same process with `LotFrontage_Missing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.340885900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "# (1) We already have a variable frontage_missing_train\n",
    "# from earlier, no additional step needed\n",
    "\n",
    "# (2) Instantiate an OrdinalEncoder for missing frontage\n",
    "encoder_frontage_missing = OrdinalEncoder()\n",
    "\n",
    "# (3) Fit the encoder on frontage_missing_train\n",
    "encoder_frontage_missing.fit(frontage_missing_train)\n",
    "\n",
    "# Inspect the categories of the fitted encoder\n",
    "encoder_frontage_missing.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.343740200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "# (4) Transform frontage_missing_train using the encoder and\n",
    "# assign the result to frontage_missing_encoded_train\n",
    "frontage_missing_encoded_train = encoder_frontage_missing.transform(frontage_missing_train)\n",
    "\n",
    "# Flatten for appropriate shape\n",
    "frontage_missing_encoded_train = frontage_missing_encoded_train.flatten()\n",
    "\n",
    "# Visually inspect frontage_missing_encoded_train\n",
    "frontage_missing_encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.345734800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "# (5) Replace value of LotFrontage_Missing\n",
    "X_train[\"LotFrontage_Missing\"] = frontage_missing_encoded_train\n",
    "\n",
    "# Visually inspect X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.348727300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we only have 1 column remaining that isn't type `float64` or `int64`!\n",
    "\n",
    "#### Note on Preprocessing Boolean Values\n",
    "For binary values like `LotFrontage_Missing`, you might see a few different approaches to preprocessing. Python treats `True` and `1` as equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.352716800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "print(True == 1)\n",
    "print(False == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that if your model is purely using Python, you actually might just be able to leave columns as type `bool` without any issues. You will likely see examples that do this. However if your model relies on C or Java \"under the hood\", this might cause problems.\n",
    "\n",
    "There is also a technique using `pandas` rather than scikit-learn for this particular conversion of boolean values to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.366679200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "df_example = pd.DataFrame(frontage_missing_train, columns=[\"LotFrontage_Missing\"])\n",
    "df_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.369671100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "df_example[\"LotFrontage_Missing\"] = df_example[\"LotFrontage_Missing\"].astype(int)\n",
    "df_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is casting every value in the `LotFrontage_Missing` column to an integer, achieving the same result as the `OrdinalEncoder` example with less code.\n",
    "\n",
    "The downside of using this approach is that it doesn't fit into a scikit-learn pipeline as neatly because it is using `pandas` to do the transformation instead of scikit-learn.\n",
    "\n",
    "In the future, you will need to make your own determination of which strategy to use!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Categories\n",
    "\n",
    "Unlike `Street` and `LotFrontage_Missing`, `FireplaceQu` has more than two categories. Therefore the process for encoding it numerically is a bit more complicated, because we will need to create multiple \"dummy\" columns that are each representing one category.\n",
    "\n",
    "To do this, we can use a `OneHotEncoder` from `sklearn.preprocessing` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)).\n",
    "\n",
    "The first several steps are very similar to all of the other transformers we've used so far, although the process of combining the data with the original data differs.\n",
    "\n",
    "In the cells below, complete steps `(0)`-`(4)` of preprocessing the `FireplaceQu` column using a `OneHotEncoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.372662600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "# (0) import OneHotEncoder from sklearn.preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# (1) Create a variable fireplace_qu_train\n",
    "# extracted from X_train\n",
    "# (double brackets due to shape expected by OHE)\n",
    "fireplace_qu_train = X_train[[\"FireplaceQu\"]]\n",
    "\n",
    "# (2) Instantiate a OneHotEncoder with categories=\"auto\",\n",
    "# sparse=False, and handle_unknown=\"ignore\"\n",
    "ohe = OneHotEncoder(categories=\"auto\", sparse=False, handle_unknown=\"ignore\")\n",
    "\n",
    "# (3) Fit the encoder on fireplace_qu_train\n",
    "ohe.fit(fireplace_qu_train)\n",
    "\n",
    "# Inspect the categories of the fitted encoder\n",
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.379085100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "\n",
    "# (4) Transform fireplace_qu_train using the encoder and\n",
    "# assign the result to fireplace_qu_encoded_train\n",
    "fireplace_qu_encoded_train = ohe.transform(fireplace_qu_train)\n",
    "\n",
    "# Visually inspect fireplace_qu_encoded_train\n",
    "fireplace_qu_encoded_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this time, unlike with `MissingIndicator`, `SimpleImputer`, or `OrdinalEncoder`, we have created multiple columns of data out of a single column. The code below converts this unlabeled NumPy array into a readable pandas dataframe in preparation for merging it back with the rest of `X_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:53.092938500Z",
     "start_time": "2023-11-21T10:07:51.399624300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Ex   Fa   Gd  N/A   Po   TA\n1023  0.0  0.0  1.0  0.0  0.0  0.0\n810   0.0  1.0  0.0  0.0  0.0  0.0\n1384  0.0  0.0  0.0  1.0  0.0  0.0\n626   0.0  0.0  0.0  0.0  0.0  1.0\n813   0.0  0.0  0.0  1.0  0.0  0.0\n...   ...  ...  ...  ...  ...  ...\n1095  0.0  0.0  1.0  0.0  0.0  0.0\n1130  0.0  0.0  0.0  0.0  0.0  1.0\n1294  0.0  0.0  0.0  1.0  0.0  0.0\n860   0.0  0.0  1.0  0.0  0.0  0.0\n1126  0.0  0.0  0.0  0.0  0.0  1.0\n\n[1095 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ex</th>\n      <th>Fa</th>\n      <th>Gd</th>\n      <th>N/A</th>\n      <th>Po</th>\n      <th>TA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1023</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>810</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1384</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>626</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>813</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1126</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1095 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# (5a) Make the transformed data into a dataframe\n",
    "fireplace_qu_encoded_train = pd.DataFrame(\n",
    "    # Pass in NumPy array\n",
    "    fireplace_qu_encoded_train,\n",
    "    # Set the column names to the categories found by OHE\n",
    "    columns=ohe.categories_[0],\n",
    "    # Set the index to match X_train's index\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# Visually inspect new dataframe\n",
    "fireplace_qu_encoded_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple notes on the code above:\n",
    "\n",
    "* The main goal of converting this into a dataframe (rather than converting `X_train` into a NumPy array, which would also allow them to be combined) is **readability** — to help you and others understand what your code is doing, and to help you debug. Eventually when you write this code as a pipeline, it will be NumPy arrays \"under the hood\".\n",
    "* We are using just the **raw categories** from `FireplaceQu` as our new dataframe columns, but you'll also see examples where a lambda function or list comprehension is used to create column names indicating the original column name, e.g. `FireplaceQu_Ex`, `FireplaceQu_Fa` rather than just `Ex`, `Fa`. This is a design decision based on readability — the scikit-learn model will work the same either way.\n",
    "* It is very important that **the index of the new dataframe matches the index of the main `X_train` dataframe**. Because we used `train_test_split`, the index of `X_train` is shuffled, so it goes `1023`, `810`, `1384` etc. instead of `0`, `1`, `2`, etc. If you don't specify an index for the new dataframe, it will assign the first record to the index `0` rather than `1023`. If you are ever merging encoded data like this and a bunch of NaNs start appearing, make sure that the indexes are lined up correctly! You also may see examples where the index of `X_train` has been reset, rather than specifying the index of the new dataframe — either way works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to drop the original `FireplaceQu` column containing the categorical data:\n",
    "\n",
    "(For previous transformations we didn't need to drop anything because we were replacing 1 column with 1 new column in place, but one-hot encoding works differently.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:53.143056200Z",
     "start_time": "2023-11-21T10:07:51.443844800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n1023  1024         120       RL         43.0     3182   Pave   NaN      Reg   \n810    811          20       RL         78.0    10140   Pave   NaN      Reg   \n1384  1385          50       RL         60.0     9060   Pave   NaN      Reg   \n626    627          20       RL          NaN    12342   Pave   NaN      IR1   \n813    814          20       RL         75.0     9750   Pave   NaN      Reg   \n...    ...         ...      ...          ...      ...    ...   ...      ...   \n1095  1096          20       RL         78.0     9317   Pave   NaN      IR1   \n1130  1131          50       RL         65.0     7804   Pave   NaN      Reg   \n1294  1295          20       RL         60.0     8172   Pave   NaN      Reg   \n860    861          50       RL         55.0     7642   Pave   NaN      Reg   \n1126  1127         120       RL         53.0     3684   Pave   NaN      Reg   \n\n     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n1023         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n810          Lvl    AllPub  ...      648     Fa  GdPrv         NaN       0   \n1384         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n626          Lvl    AllPub  ...        0    NaN   GdWo        Shed     600   \n813          Lvl    AllPub  ...        0    NaN    NaN        Shed     500   \n...          ...       ...  ...      ...    ...    ...         ...     ...   \n1095         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1130         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n1294         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n860          Lvl    AllPub  ...        0    NaN  GdPrv         NaN       0   \n1126         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n\n     MoSold YrSold  SaleType  SaleCondition  LotFrontage_Missing  \n1023      5   2008        WD         Normal                False  \n810       1   2006        WD         Normal                False  \n1384     10   2009        WD         Normal                False  \n626       8   2007        WD         Normal                 True  \n813       4   2007       COD         Normal                False  \n...     ...    ...       ...            ...                  ...  \n1095      3   2007        WD         Normal                False  \n1130     12   2009        WD         Normal                False  \n1294      4   2006        WD         Normal                False  \n860       6   2007        WD         Normal                False  \n1126      6   2009        WD         Normal                False  \n\n[1095 rows x 80 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>LotFrontage_Missing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1023</th>\n      <td>1024</td>\n      <td>120</td>\n      <td>RL</td>\n      <td>43.0</td>\n      <td>3182</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>810</th>\n      <td>811</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>78.0</td>\n      <td>10140</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>648</td>\n      <td>Fa</td>\n      <td>GdPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1384</th>\n      <td>1385</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9060</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>10</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>626</th>\n      <td>627</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>12342</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdWo</td>\n      <td>Shed</td>\n      <td>600</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>813</th>\n      <td>814</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>9750</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Shed</td>\n      <td>500</td>\n      <td>4</td>\n      <td>2007</td>\n      <td>COD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>1096</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>78.0</td>\n      <td>9317</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>1131</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>7804</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>1295</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>8172</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>861</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>55.0</td>\n      <td>7642</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>GdPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1126</th>\n      <td>1127</td>\n      <td>120</td>\n      <td>RL</td>\n      <td>53.0</td>\n      <td>3684</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>1095 rows × 80 columns</p>\n</div>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# (5b) Drop original FireplaceQu column\n",
    "X_train.drop(\"FireplaceQu\", axis=1, inplace=True)\n",
    "\n",
    "# Visually inspect X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to concatenate the new dataframe together with the original `X_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:53.195943900Z",
     "start_time": "2023-11-21T10:07:51.475256100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n1023  1024         120       RL         43.0     3182   Pave   NaN      Reg   \n810    811          20       RL         78.0    10140   Pave   NaN      Reg   \n1384  1385          50       RL         60.0     9060   Pave   NaN      Reg   \n626    627          20       RL          NaN    12342   Pave   NaN      IR1   \n813    814          20       RL         75.0     9750   Pave   NaN      Reg   \n...    ...         ...      ...          ...      ...    ...   ...      ...   \n1095  1096          20       RL         78.0     9317   Pave   NaN      IR1   \n1130  1131          50       RL         65.0     7804   Pave   NaN      Reg   \n1294  1295          20       RL         60.0     8172   Pave   NaN      Reg   \n860    861          50       RL         55.0     7642   Pave   NaN      Reg   \n1126  1127         120       RL         53.0     3684   Pave   NaN      Reg   \n\n     LandContour Utilities  ... YrSold SaleType SaleCondition  \\\n1023         Lvl    AllPub  ...   2008       WD        Normal   \n810          Lvl    AllPub  ...   2006       WD        Normal   \n1384         Lvl    AllPub  ...   2009       WD        Normal   \n626          Lvl    AllPub  ...   2007       WD        Normal   \n813          Lvl    AllPub  ...   2007      COD        Normal   \n...          ...       ...  ...    ...      ...           ...   \n1095         Lvl    AllPub  ...   2007       WD        Normal   \n1130         Lvl    AllPub  ...   2009       WD        Normal   \n1294         Lvl    AllPub  ...   2006       WD        Normal   \n860          Lvl    AllPub  ...   2007       WD        Normal   \n1126         Lvl    AllPub  ...   2009       WD        Normal   \n\n     LotFrontage_Missing   Ex   Fa   Gd  N/A   Po   TA  \n1023               False  0.0  0.0  1.0  0.0  0.0  0.0  \n810                False  0.0  1.0  0.0  0.0  0.0  0.0  \n1384               False  0.0  0.0  0.0  1.0  0.0  0.0  \n626                 True  0.0  0.0  0.0  0.0  0.0  1.0  \n813                False  0.0  0.0  0.0  1.0  0.0  0.0  \n...                  ...  ...  ...  ...  ...  ...  ...  \n1095               False  0.0  0.0  1.0  0.0  0.0  0.0  \n1130               False  0.0  0.0  0.0  0.0  0.0  1.0  \n1294               False  0.0  0.0  0.0  1.0  0.0  0.0  \n860                False  0.0  0.0  1.0  0.0  0.0  0.0  \n1126               False  0.0  0.0  0.0  0.0  0.0  1.0  \n\n[1095 rows x 86 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>LotFrontage_Missing</th>\n      <th>Ex</th>\n      <th>Fa</th>\n      <th>Gd</th>\n      <th>N/A</th>\n      <th>Po</th>\n      <th>TA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1023</th>\n      <td>1024</td>\n      <td>120</td>\n      <td>RL</td>\n      <td>43.0</td>\n      <td>3182</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>810</th>\n      <td>811</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>78.0</td>\n      <td>10140</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1384</th>\n      <td>1385</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9060</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>626</th>\n      <td>627</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>12342</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>813</th>\n      <td>814</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>9750</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>2007</td>\n      <td>COD</td>\n      <td>Normal</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>1096</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>78.0</td>\n      <td>9317</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>1131</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>7804</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>1295</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>8172</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>861</td>\n      <td>50</td>\n      <td>RL</td>\n      <td>55.0</td>\n      <td>7642</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1126</th>\n      <td>1127</td>\n      <td>120</td>\n      <td>RL</td>\n      <td>53.0</td>\n      <td>3684</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>2009</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1095 rows × 86 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# (5c) Concatenate the new dataframe with current X_train\n",
    "X_train = pd.concat([X_train, fireplace_qu_encoded_train], axis=1)\n",
    "\n",
    "# Visually inspect X_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:07:53.240794200Z",
     "start_time": "2023-11-21T10:07:51.569661300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1095 entries, 1023 to 1126\n",
      "Data columns (total 86 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Id                   1095 non-null   int64  \n",
      " 1   MSSubClass           1095 non-null   int64  \n",
      " 2   MSZoning             1095 non-null   object \n",
      " 3   LotFrontage          895 non-null    float64\n",
      " 4   LotArea              1095 non-null   int64  \n",
      " 5   Street               1095 non-null   object \n",
      " 6   Alley                70 non-null     object \n",
      " 7   LotShape             1095 non-null   object \n",
      " 8   LandContour          1095 non-null   object \n",
      " 9   Utilities            1095 non-null   object \n",
      " 10  LotConfig            1095 non-null   object \n",
      " 11  LandSlope            1095 non-null   object \n",
      " 12  Neighborhood         1095 non-null   object \n",
      " 13  Condition1           1095 non-null   object \n",
      " 14  Condition2           1095 non-null   object \n",
      " 15  BldgType             1095 non-null   object \n",
      " 16  HouseStyle           1095 non-null   object \n",
      " 17  OverallQual          1095 non-null   int64  \n",
      " 18  OverallCond          1095 non-null   int64  \n",
      " 19  YearBuilt            1095 non-null   int64  \n",
      " 20  YearRemodAdd         1095 non-null   int64  \n",
      " 21  RoofStyle            1095 non-null   object \n",
      " 22  RoofMatl             1095 non-null   object \n",
      " 23  Exterior1st          1095 non-null   object \n",
      " 24  Exterior2nd          1095 non-null   object \n",
      " 25  MasVnrType           456 non-null    object \n",
      " 26  MasVnrArea           1091 non-null   float64\n",
      " 27  ExterQual            1095 non-null   object \n",
      " 28  ExterCond            1095 non-null   object \n",
      " 29  Foundation           1095 non-null   object \n",
      " 30  BsmtQual             1068 non-null   object \n",
      " 31  BsmtCond             1068 non-null   object \n",
      " 32  BsmtExposure         1068 non-null   object \n",
      " 33  BsmtFinType1         1068 non-null   object \n",
      " 34  BsmtFinSF1           1095 non-null   int64  \n",
      " 35  BsmtFinType2         1068 non-null   object \n",
      " 36  BsmtFinSF2           1095 non-null   int64  \n",
      " 37  BsmtUnfSF            1095 non-null   int64  \n",
      " 38  TotalBsmtSF          1095 non-null   int64  \n",
      " 39  Heating              1095 non-null   object \n",
      " 40  HeatingQC            1095 non-null   object \n",
      " 41  CentralAir           1095 non-null   object \n",
      " 42  Electrical           1094 non-null   object \n",
      " 43  1stFlrSF             1095 non-null   int64  \n",
      " 44  2ndFlrSF             1095 non-null   int64  \n",
      " 45  LowQualFinSF         1095 non-null   int64  \n",
      " 46  GrLivArea            1095 non-null   int64  \n",
      " 47  BsmtFullBath         1095 non-null   int64  \n",
      " 48  BsmtHalfBath         1095 non-null   int64  \n",
      " 49  FullBath             1095 non-null   int64  \n",
      " 50  HalfBath             1095 non-null   int64  \n",
      " 51  BedroomAbvGr         1095 non-null   int64  \n",
      " 52  KitchenAbvGr         1095 non-null   int64  \n",
      " 53  KitchenQual          1095 non-null   object \n",
      " 54  TotRmsAbvGrd         1095 non-null   int64  \n",
      " 55  Functional           1095 non-null   object \n",
      " 56  Fireplaces           1095 non-null   int64  \n",
      " 57  GarageType           1037 non-null   object \n",
      " 58  GarageYrBlt          1037 non-null   float64\n",
      " 59  GarageFinish         1037 non-null   object \n",
      " 60  GarageCars           1095 non-null   int64  \n",
      " 61  GarageArea           1095 non-null   int64  \n",
      " 62  GarageQual           1037 non-null   object \n",
      " 63  GarageCond           1037 non-null   object \n",
      " 64  PavedDrive           1095 non-null   object \n",
      " 65  WoodDeckSF           1095 non-null   int64  \n",
      " 66  OpenPorchSF          1095 non-null   int64  \n",
      " 67  EnclosedPorch        1095 non-null   int64  \n",
      " 68  3SsnPorch            1095 non-null   int64  \n",
      " 69  ScreenPorch          1095 non-null   int64  \n",
      " 70  PoolArea             1095 non-null   int64  \n",
      " 71  PoolQC               6 non-null      object \n",
      " 72  Fence                218 non-null    object \n",
      " 73  MiscFeature          43 non-null     object \n",
      " 74  MiscVal              1095 non-null   int64  \n",
      " 75  MoSold               1095 non-null   int64  \n",
      " 76  YrSold               1095 non-null   int64  \n",
      " 77  SaleType             1095 non-null   object \n",
      " 78  SaleCondition        1095 non-null   object \n",
      " 79  LotFrontage_Missing  1095 non-null   bool   \n",
      " 80  Ex                   1095 non-null   float64\n",
      " 81  Fa                   1095 non-null   float64\n",
      " 82  Gd                   1095 non-null   float64\n",
      " 83  N/A                  1095 non-null   float64\n",
      " 84  Po                   1095 non-null   float64\n",
      " 85  TA                   1095 non-null   float64\n",
      "dtypes: bool(1), float64(9), int64(34), object(42)\n",
      "memory usage: 736.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, everything is numeric now! We have completed the minimum necessary preprocessing to use these features in a scikit-learn model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T10:07:51.605999300Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'RL'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Run this cell without changes\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[0;32m   1150\u001B[0m ):\n\u001B[1;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001B[0m, in \u001B[0;36mLinearRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    674\u001B[0m n_jobs_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs\n\u001B[0;32m    676\u001B[0m accept_sparse \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpositive \u001B[38;5;28;01melse\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoo\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m--> 678\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[0;32m    679\u001B[0m     X, y, accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse, y_numeric\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, multi_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    680\u001B[0m )\n\u001B[0;32m    682\u001B[0m has_sw \u001B[38;5;241m=\u001B[39m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_sw:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    619\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    620\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 621\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    622\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1142\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1144\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1145\u001B[0m     )\n\u001B[1;32m-> 1147\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m   1148\u001B[0m     X,\n\u001B[0;32m   1149\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[0;32m   1150\u001B[0m     accept_large_sparse\u001B[38;5;241m=\u001B[39maccept_large_sparse,\n\u001B[0;32m   1151\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   1152\u001B[0m     order\u001B[38;5;241m=\u001B[39morder,\n\u001B[0;32m   1153\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m   1154\u001B[0m     force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite,\n\u001B[0;32m   1155\u001B[0m     ensure_2d\u001B[38;5;241m=\u001B[39mensure_2d,\n\u001B[0;32m   1156\u001B[0m     allow_nd\u001B[38;5;241m=\u001B[39mallow_nd,\n\u001B[0;32m   1157\u001B[0m     ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n\u001B[0;32m   1158\u001B[0m     ensure_min_features\u001B[38;5;241m=\u001B[39mensure_min_features,\n\u001B[0;32m   1159\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[0;32m   1160\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1161\u001B[0m )\n\u001B[0;32m   1163\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[0;32m   1165\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:838\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    833\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pandas_requires_conversion:\n\u001B[0;32m    834\u001B[0m     \u001B[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001B[39;00m\n\u001B[0;32m    835\u001B[0m     \u001B[38;5;66;03m# nans\u001B[39;00m\n\u001B[0;32m    836\u001B[0m     \u001B[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001B[39;00m\n\u001B[0;32m    837\u001B[0m     new_dtype \u001B[38;5;241m=\u001B[39m dtype_orig \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m dtype\n\u001B[1;32m--> 838\u001B[0m     array \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mastype(new_dtype)\n\u001B[0;32m    839\u001B[0m     \u001B[38;5;66;03m# Since we converted here, we do not need to convert again later\u001B[39;00m\n\u001B[0;32m    840\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6324\u001B[0m, in \u001B[0;36mNDFrame.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   6317\u001B[0m     results \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   6318\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miloc[:, i]\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m   6319\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns))\n\u001B[0;32m   6320\u001B[0m     ]\n\u001B[0;32m   6322\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6323\u001B[0m     \u001B[38;5;66;03m# else, only a single dtype is given\u001B[39;00m\n\u001B[1;32m-> 6324\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39mastype(dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m   6325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_data)\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6327\u001B[0m \u001B[38;5;66;03m# GH 33113: handle empty frame or series\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001B[0m, in \u001B[0;36mBaseBlockManager.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    449\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 451\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply(\n\u001B[0;32m    452\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    453\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m    454\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m    455\u001B[0m     errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    456\u001B[0m     using_cow\u001B[38;5;241m=\u001B[39musing_copy_on_write(),\n\u001B[0;32m    457\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001B[0m, in \u001B[0;36mBaseBlockManager.apply\u001B[1;34m(self, f, align_keys, **kwargs)\u001B[0m\n\u001B[0;32m    350\u001B[0m         applied \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mapply(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    351\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 352\u001B[0m         applied \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(b, f)(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     result_blocks \u001B[38;5;241m=\u001B[39m extend_blocks(applied, result_blocks)\n\u001B[0;32m    355\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mfrom_blocks(result_blocks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001B[0m, in \u001B[0;36mBlock.astype\u001B[1;34m(self, dtype, copy, errors, using_cow)\u001B[0m\n\u001B[0;32m    491\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;124;03mCoerce to the new dtype.\u001B[39;00m\n\u001B[0;32m    493\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    507\u001B[0m \u001B[38;5;124;03mBlock\u001B[39;00m\n\u001B[0;32m    508\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    509\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m--> 511\u001B[0m new_values \u001B[38;5;241m=\u001B[39m astype_array_safe(values, dtype, copy\u001B[38;5;241m=\u001B[39mcopy, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m    513\u001B[0m new_values \u001B[38;5;241m=\u001B[39m maybe_coerce_values(new_values)\n\u001B[0;32m    515\u001B[0m refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001B[0m, in \u001B[0;36mastype_array_safe\u001B[1;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    239\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtype\u001B[38;5;241m.\u001B[39mnumpy_dtype\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 242\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m astype_array(values, dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[0;32m    244\u001B[0m     \u001B[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001B[39;00m\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;66;03m#  trying to convert to float\u001B[39;00m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:187\u001B[0m, in \u001B[0;36mastype_array\u001B[1;34m(values, dtype, copy)\u001B[0m\n\u001B[0;32m    184\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 187\u001B[0m     values \u001B[38;5;241m=\u001B[39m _astype_nansafe(values, dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    189\u001B[0m \u001B[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001B[39;00m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, np\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(values\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138\u001B[0m, in \u001B[0;36m_astype_nansafe\u001B[1;34m(arr, dtype, copy, skipna)\u001B[0m\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(arr\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(dtype):\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001B[39;00m\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'RL'"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, no error this time.\n",
    "\n",
    "Let's use cross validation to take a look at the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:08:12.839378400Z",
     "start_time": "2023-11-21T10:08:12.433390Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 678, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 838, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6324, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 451, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 352, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 511, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 242, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 187, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 138, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'RL'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[67], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Run this cell without changes\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_val_score\n\u001B[1;32m----> 4\u001B[0m cross_val_score(model, X_train, y_train, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001B[0m, in \u001B[0;36mcross_val_score\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[0;32m    559\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[0;32m    560\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[1;32m--> 562\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m cross_validate(\n\u001B[0;32m    563\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[0;32m    564\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m    565\u001B[0m     y\u001B[38;5;241m=\u001B[39my,\n\u001B[0;32m    566\u001B[0m     groups\u001B[38;5;241m=\u001B[39mgroups,\n\u001B[0;32m    567\u001B[0m     scoring\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m: scorer},\n\u001B[0;32m    568\u001B[0m     cv\u001B[38;5;241m=\u001B[39mcv,\n\u001B[0;32m    569\u001B[0m     n_jobs\u001B[38;5;241m=\u001B[39mn_jobs,\n\u001B[0;32m    570\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m    571\u001B[0m     fit_params\u001B[38;5;241m=\u001B[39mfit_params,\n\u001B[0;32m    572\u001B[0m     pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch,\n\u001B[0;32m    573\u001B[0m     error_score\u001B[38;5;241m=\u001B[39merror_score,\n\u001B[0;32m    574\u001B[0m )\n\u001B[0;32m    575\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    209\u001B[0m         )\n\u001B[0;32m    210\u001B[0m     ):\n\u001B[1;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    221\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:328\u001B[0m, in \u001B[0;36mcross_validate\u001B[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[0m\n\u001B[0;32m    308\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m    309\u001B[0m results \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[0;32m    310\u001B[0m     delayed(_fit_and_score)(\n\u001B[0;32m    311\u001B[0m         clone(estimator),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    325\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m indices\n\u001B[0;32m    326\u001B[0m )\n\u001B[1;32m--> 328\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[0;32m    330\u001B[0m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[0;32m    331\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(scoring):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[0;32m    408\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    409\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    410\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    411\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    412\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    413\u001B[0m     )\n\u001B[1;32m--> 414\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[0;32m    416\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    417\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    418\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    419\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    423\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    424\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 678, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 838, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6324, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 451, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 352, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 511, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 242, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 187, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 138, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'RL'\n"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(model, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not terrible, we are explaining between 66% and 80% of the variance in the target with our current feature set. Let's say that this is our final model and move on to preparing the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocess Test Data\n",
    "\n",
    "> Apply Steps 1-3 to the test data in order to perform a final model evaluation.\n",
    "\n",
    "This part is done for you, and it should work automatically, assuming you didn't change the names of any of the transformer objects. Note that we are intentionally **not instantiating or fitting the transformers** here, because you always want to fit transformers on the training data only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1: Drop Irrelevant Columns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:08:15.746394Z",
     "start_time": "2023-11-21T10:08:15.699078900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "X_test = X_test.loc[:, relevant_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2: Handle Missing Values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:08:16.879930800Z",
     "start_time": "2023-11-21T10:08:16.832007900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LotFrontage            0\nLotArea                0\nStreet                 0\nOverallQual            0\nOverallCond            0\nYearBuilt              0\nYearRemodAdd           0\nGrLivArea              0\nFullBath               0\nBedroomAbvGr           0\nTotRmsAbvGrd           0\nFireplaces             0\nFireplaceQu            0\nMoSold                 0\nYrSold                 0\nLotFrontage_Missing    0\ndtype: int64"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Replace FireplaceQu NaNs with \"N/A\"s\n",
    "X_test[\"FireplaceQu\"] = X_test[\"FireplaceQu\"].fillna(\"N/A\")\n",
    "\n",
    "# Add missing indicator for lot frontage\n",
    "frontage_test = X_test[[\"LotFrontage\"]]\n",
    "frontage_missing_test = missing_indicator.transform(frontage_test)\n",
    "X_test[\"LotFrontage_Missing\"] = frontage_missing_test\n",
    "\n",
    "# Impute missing lot frontage values\n",
    "frontage_imputed_test = imputer.transform(frontage_test)\n",
    "X_test[\"LotFrontage\"] = frontage_imputed_test\n",
    "\n",
    "# Check that there are no more missing values\n",
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 3: Convert Categorical Features into Numbers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:08:18.122224400Z",
     "start_time": "2023-11-21T10:08:18.051292Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sparr\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but OrdinalEncoder was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "      LotFrontage  LotArea  Street  OverallQual  OverallCond  YearBuilt  \\\n892          70.0     8414     1.0            6            8       1963   \n1105         98.0    12256     1.0            8            5       1994   \n413          56.0     8960     1.0            5            6       1927   \n522          50.0     5000     1.0            6            7       1947   \n1036         89.0    12898     1.0            9            5       2007   \n...           ...      ...     ...          ...          ...        ...   \n988          70.0    12046     1.0            6            6       1976   \n243          75.0    10762     1.0            6            6       1980   \n1342         70.0     9375     1.0            8            5       2002   \n1057         70.0    29959     1.0            7            6       1994   \n1418         71.0     9204     1.0            5            5       1963   \n\n      YearRemodAdd  GrLivArea  FullBath  BedroomAbvGr  ...  Fireplaces  \\\n892           2003       1068         1             3  ...           0   \n1105          1995       2622         2             3  ...           2   \n413           1950       1028         1             2  ...           1   \n522           1950       1664         2             3  ...           2   \n1036          2008       1620         2             2  ...           1   \n...            ...        ...       ...           ...  ...         ...   \n988           1976       2030         2             4  ...           1   \n243           1980       1217         1             3  ...           1   \n1342          2002       2169         2             3  ...           1   \n1057          1994       1850         2             3  ...           1   \n1418          1963       1144         1             3  ...           0   \n\n      MoSold  YrSold  LotFrontage_Missing   Ex   Fa   Gd  N/A   Po   TA  \n892        2    2006                  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n1105       4    2010                  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n413        3    2010                  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n522       10    2006                  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n1036       9    2009                  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n...      ...     ...                  ...  ...  ...  ...  ...  ...  ...  \n988        6    2007                  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n243        4    2009                  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n1342       8    2007                  1.0  0.0  0.0  1.0  0.0  0.0  0.0  \n1057       1    2009                  1.0  0.0  0.0  1.0  0.0  0.0  0.0  \n1418       8    2008                  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n\n[365 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>GrLivArea</th>\n      <th>FullBath</th>\n      <th>BedroomAbvGr</th>\n      <th>...</th>\n      <th>Fireplaces</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>LotFrontage_Missing</th>\n      <th>Ex</th>\n      <th>Fa</th>\n      <th>Gd</th>\n      <th>N/A</th>\n      <th>Po</th>\n      <th>TA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>892</th>\n      <td>70.0</td>\n      <td>8414</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>8</td>\n      <td>1963</td>\n      <td>2003</td>\n      <td>1068</td>\n      <td>1</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1105</th>\n      <td>98.0</td>\n      <td>12256</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>5</td>\n      <td>1994</td>\n      <td>1995</td>\n      <td>2622</td>\n      <td>2</td>\n      <td>3</td>\n      <td>...</td>\n      <td>2</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>56.0</td>\n      <td>8960</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1927</td>\n      <td>1950</td>\n      <td>1028</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2010</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>522</th>\n      <td>50.0</td>\n      <td>5000</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>7</td>\n      <td>1947</td>\n      <td>1950</td>\n      <td>1664</td>\n      <td>2</td>\n      <td>3</td>\n      <td>...</td>\n      <td>2</td>\n      <td>10</td>\n      <td>2006</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1036</th>\n      <td>89.0</td>\n      <td>12898</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>2008</td>\n      <td>1620</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>9</td>\n      <td>2009</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>988</th>\n      <td>70.0</td>\n      <td>12046</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>2030</td>\n      <td>2</td>\n      <td>4</td>\n      <td>...</td>\n      <td>1</td>\n      <td>6</td>\n      <td>2007</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>75.0</td>\n      <td>10762</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>6</td>\n      <td>1980</td>\n      <td>1980</td>\n      <td>1217</td>\n      <td>1</td>\n      <td>3</td>\n      <td>...</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2009</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1342</th>\n      <td>70.0</td>\n      <td>9375</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>5</td>\n      <td>2002</td>\n      <td>2002</td>\n      <td>2169</td>\n      <td>2</td>\n      <td>3</td>\n      <td>...</td>\n      <td>1</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1057</th>\n      <td>70.0</td>\n      <td>29959</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>6</td>\n      <td>1994</td>\n      <td>1994</td>\n      <td>1850</td>\n      <td>2</td>\n      <td>3</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2009</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1418</th>\n      <td>71.0</td>\n      <td>9204</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1963</td>\n      <td>1963</td>\n      <td>1144</td>\n      <td>1</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2008</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>365 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Encode street type\n",
    "street_test = X_test[[\"Street\"]]\n",
    "street_encoded_test = encoder_street.transform(street_test).flatten()\n",
    "X_test[\"Street\"] = street_encoded_test\n",
    "\n",
    "# Encode frontage missing\n",
    "frontage_missing_test = X_test[[\"LotFrontage_Missing\"]]\n",
    "frontage_missing_encoded_test = encoder_frontage_missing.transform(frontage_missing_test).flatten()\n",
    "X_test[\"LotFrontage_Missing\"] = frontage_missing_encoded_test\n",
    "\n",
    "# One-hot encode fireplace quality\n",
    "fireplace_qu_test = X_test[[\"FireplaceQu\"]]\n",
    "fireplace_qu_encoded_test = ohe.transform(fireplace_qu_test)\n",
    "fireplace_qu_encoded_test = pd.DataFrame(\n",
    "    fireplace_qu_encoded_test,\n",
    "    columns=ohe.categories_[0],\n",
    "    index=X_test.index\n",
    ")\n",
    "X_test.drop(\"FireplaceQu\", axis=1, inplace=True)\n",
    "X_test = pd.concat([X_test, fireplace_qu_encoded_test], axis=1)\n",
    "\n",
    "# Visually inspect X_test\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model on the full training set, evaluate on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T10:08:19.936568500Z",
     "start_time": "2023-11-21T10:08:19.725863600Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'RL'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[71], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Run this cell without changes\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39mscore(X_test, y_test)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[0;32m   1150\u001B[0m ):\n\u001B[1;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001B[0m, in \u001B[0;36mLinearRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    674\u001B[0m n_jobs_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs\n\u001B[0;32m    676\u001B[0m accept_sparse \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpositive \u001B[38;5;28;01melse\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoo\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m--> 678\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[0;32m    679\u001B[0m     X, y, accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse, y_numeric\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, multi_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    680\u001B[0m )\n\u001B[0;32m    682\u001B[0m has_sw \u001B[38;5;241m=\u001B[39m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_sw:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    619\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    620\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 621\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    622\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1142\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1144\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1145\u001B[0m     )\n\u001B[1;32m-> 1147\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m   1148\u001B[0m     X,\n\u001B[0;32m   1149\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[0;32m   1150\u001B[0m     accept_large_sparse\u001B[38;5;241m=\u001B[39maccept_large_sparse,\n\u001B[0;32m   1151\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m   1152\u001B[0m     order\u001B[38;5;241m=\u001B[39morder,\n\u001B[0;32m   1153\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m   1154\u001B[0m     force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite,\n\u001B[0;32m   1155\u001B[0m     ensure_2d\u001B[38;5;241m=\u001B[39mensure_2d,\n\u001B[0;32m   1156\u001B[0m     allow_nd\u001B[38;5;241m=\u001B[39mallow_nd,\n\u001B[0;32m   1157\u001B[0m     ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n\u001B[0;32m   1158\u001B[0m     ensure_min_features\u001B[38;5;241m=\u001B[39mensure_min_features,\n\u001B[0;32m   1159\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[0;32m   1160\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1161\u001B[0m )\n\u001B[0;32m   1163\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[0;32m   1165\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:838\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    833\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pandas_requires_conversion:\n\u001B[0;32m    834\u001B[0m     \u001B[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001B[39;00m\n\u001B[0;32m    835\u001B[0m     \u001B[38;5;66;03m# nans\u001B[39;00m\n\u001B[0;32m    836\u001B[0m     \u001B[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001B[39;00m\n\u001B[0;32m    837\u001B[0m     new_dtype \u001B[38;5;241m=\u001B[39m dtype_orig \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m dtype\n\u001B[1;32m--> 838\u001B[0m     array \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mastype(new_dtype)\n\u001B[0;32m    839\u001B[0m     \u001B[38;5;66;03m# Since we converted here, we do not need to convert again later\u001B[39;00m\n\u001B[0;32m    840\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6324\u001B[0m, in \u001B[0;36mNDFrame.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   6317\u001B[0m     results \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   6318\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miloc[:, i]\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m   6319\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns))\n\u001B[0;32m   6320\u001B[0m     ]\n\u001B[0;32m   6322\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6323\u001B[0m     \u001B[38;5;66;03m# else, only a single dtype is given\u001B[39;00m\n\u001B[1;32m-> 6324\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39mastype(dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m   6325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_data)\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6327\u001B[0m \u001B[38;5;66;03m# GH 33113: handle empty frame or series\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001B[0m, in \u001B[0;36mBaseBlockManager.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    449\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 451\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply(\n\u001B[0;32m    452\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    453\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[0;32m    454\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m    455\u001B[0m     errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    456\u001B[0m     using_cow\u001B[38;5;241m=\u001B[39musing_copy_on_write(),\n\u001B[0;32m    457\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001B[0m, in \u001B[0;36mBaseBlockManager.apply\u001B[1;34m(self, f, align_keys, **kwargs)\u001B[0m\n\u001B[0;32m    350\u001B[0m         applied \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mapply(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    351\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 352\u001B[0m         applied \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(b, f)(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     result_blocks \u001B[38;5;241m=\u001B[39m extend_blocks(applied, result_blocks)\n\u001B[0;32m    355\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mfrom_blocks(result_blocks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001B[0m, in \u001B[0;36mBlock.astype\u001B[1;34m(self, dtype, copy, errors, using_cow)\u001B[0m\n\u001B[0;32m    491\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;124;03mCoerce to the new dtype.\u001B[39;00m\n\u001B[0;32m    493\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    507\u001B[0m \u001B[38;5;124;03mBlock\u001B[39;00m\n\u001B[0;32m    508\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    509\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m--> 511\u001B[0m new_values \u001B[38;5;241m=\u001B[39m astype_array_safe(values, dtype, copy\u001B[38;5;241m=\u001B[39mcopy, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m    513\u001B[0m new_values \u001B[38;5;241m=\u001B[39m maybe_coerce_values(new_values)\n\u001B[0;32m    515\u001B[0m refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001B[0m, in \u001B[0;36mastype_array_safe\u001B[1;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    239\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtype\u001B[38;5;241m.\u001B[39mnumpy_dtype\n\u001B[0;32m    241\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 242\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m astype_array(values, dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[0;32m    244\u001B[0m     \u001B[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001B[39;00m\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;66;03m#  trying to convert to float\u001B[39;00m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:187\u001B[0m, in \u001B[0;36mastype_array\u001B[1;34m(values, dtype, copy)\u001B[0m\n\u001B[0;32m    184\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 187\u001B[0m     values \u001B[38;5;241m=\u001B[39m _astype_nansafe(values, dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    189\u001B[0m \u001B[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001B[39;00m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, np\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(values\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138\u001B[0m, in \u001B[0;36m_astype_nansafe\u001B[1;34m(arr, dtype, copy, skipna)\u001B[0m\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(arr\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(dtype):\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001B[39;00m\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'RL'"
     ]
    }
   ],
   "source": [
    "# Run this cell without changes\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, that worked! Now we have completed the full process of preprocessing the Ames Housing data in preparation for machine learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this cumulative lab, you used various techniques to prepare the Ames Housing data for modeling. You filtered down the full dataset to only relevant columns, filled in missing values, and converted categorical data into numeric data. Each time, you practiced the scikit-learn transformer workflow by instantiating the transformer, fitting on the relevant training data, transforming the training data, and transforming the test data at the end (without re-instantiating or re-fitting the transformer object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
